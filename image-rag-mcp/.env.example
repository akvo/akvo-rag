# Chat Provider, remember to set the api key / base url / model for the provider
CHAT_PROVIDER=openai

# Embeddings Provider, remember to set the api key / base url / model for the provider
EMBEDDINGS_PROVIDER=openai

# OpenAI settings (required if CHAT_PROVIDER=openai or EMBEDDINGS_PROVIDER=openai)
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o
OPENAI_EMBEDDINGS_MODEL=text-embedding-3-large


# Ollama settings (required if CHAT_PROVIDER=ollama, in docker compose, use host.docker.internal instead of localhost)

# If you are using macOS with docker-compose, you can use host.docker.internal
# OLLAMA_API_BASE=http://host.docker.internal:11434

# If you used a compiled installation, you can use http://localhost:11434
# OLLAMA_API_BASE=http://localhost:11434

# If you are a Linux server using docker-compose, you need to use the host machine's IP address.
OLLAMA_API_BASE=http://localhost:11434
OLLAMA_MODEL=deepseek-r1:7b
# Ollama Embedding Model (required if EMBEDDINGS_PROVIDER=ollama)
OLLAMA_EMBEDDINGS_MODEL=nomic-embed-text


# Chroma DB settings (required if VECTOR_STORE_TYPE=chroma)
CHROMA_DB_HOST=chromadb
CHROMA_DB_PORT=8000
